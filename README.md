# chatbot_basic

# Installation modules:


pip install streamlit transformers torch



# selection Model


Model Selection: The most important change is on line 5. I've switched the MODEL_NAME from "microsoft/DialoGPT-medium" to "google/gemma-2b-it". The "it" in the name stands for "instruction-tuned," which means it has been specifically trained to follow instructions and answer questions, making it much more suitable for your use case.

Input Formatting: The gemma model requires the entire chat history to be passed to it as a single, specially formatted tensor. I've updated the logic inside the if prompt := st.chat_input(...) block to build a full conversation history list and then use st.session_state.tokenizer.apply_chat_template() to format it correctly for the model. This is the new standard for modern conversational models and makes the chatbot more robust.

Generation Parameters: I've also slightly adjusted the generate parameters (max_length, top_k, top_p, temperature) to values that are commonly used and work well with the gemma model.
ğŸ§  Ollama-Powered Python Agent with Streamlit

This project is a locally hosted AI agent built using 
, , and 

. It interprets natural language commands, generates Python code, and executes it live â€” all without needing an API key or internet access.
ğŸš€ Features

    âœ… Local LLM (Mistral via Ollama)

    ğŸ§ª Python code execution using LangChainâ€™s PythonREPLTool

    ğŸ§  Agent reasoning with Thought â†’ Action â†’ Observation

    ğŸ“š Injected knowledge base for Indian state capitals

    ğŸ–¥ï¸ Streamlit UI with live agent feedback

    ğŸ” Fully offline â€” no external APIs required

ğŸ“¦ Requirements


pip install streamlit langchain langchain_experimental langchain_community


To pull the ollama model

curl -fsSL https://ollama.ai/install.sh | sh
ollama pull mistral


chatbot_basic/
â”œâ”€â”€ agent_app.py         # Main Streamlit app
â”œâ”€â”€ README.md            # Project documentation

Usuage

streamlit run agent_app.py



Streamlit learning 


Streamlit â€“usage 

Allows us to create data applications

1. Deploy a machine learning model

2. Deploy a dashboard

3. Share a data science project


Streamlit detects the changes and displays them on the browser â†’ Make changes to your file 


With caching we can avoid running expensive code

â†’ @st.cache_data

1. Serializable objects
    -- Functions
    -- API calls
    -- Data frames

â†’ @st.cache_resource

	Unserializable objects
	-- ML Models
	-- Database Connections
Features of streamlit

1. Display text
2. Display plots
3. Interactivity (radio Buttons, check boxes, forms,sliders etc..)
4. Multi-page apps
5. Stateful apps
6. Data base connections



Default port for running the streamlit -- 8501



Basic headers usage

Title of the web app 

â†’ st.title(â€œfirst appâ€)

headers

â†’ st.header(â€œBasic hello world appâ€)

still requires any sub headers we can use the subheader

â†’ st.subheader(â€œBasic application for the hello world appâ€)


Let say if we want to have the more subheaders then we can go for the markdown option


â†’ st.markdown()


Caption :

â†’ st.caption()


â†’ Code implementation we can use  the st.code (â€œâ€â€™ import pandas as pd pd.read_csv
(my_csv_file)â€œâ€â€)


Text option 

â†’ st.text()


Latex :

let say if we want to add any kind of equation we can use the Latex method


â†’ st.latex()